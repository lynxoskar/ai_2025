## this is the work plan for our presentation

## we will have a folder with sources where we download items of interest

## i will dump outlining thoughts here and include into the presentation




### line of thought - development
> The beaver told the rabbit as they stared at the Hoover Dam: No, I didn’t build it myself, but it’s based on an idea of mine.”
— Charles Hard Townes"""  

- ideas have been around. Deep learing and neuralnets are old ideas. 
- But the enablers  - hardware - attention is all you need paper tranformers - big corpus of information made it happen 

- is it the big ideas that have changed or is it environment - example guns germs and steel; "writing have been around for long, but only when enouogh people reads it makes sence for a gutenberg revolution"

- leeds to current day. This is macro scale, what does that mean for lynx in a microscale. Need enablers, need to create oportunitites for radical change. Data - Innovation - Trust

- replacement vs augmentation


### line of thougth - impact and realisation
"""“The future is already here – it's just not evenly distributed.”
― William Gibson"""
- not. Andrej Karpathey of its every mans hand atm
- leveling the field

sunken cost fallacy moot

redo somthing you know the internals of easier then ever

probablistic vs determenistic programing

examples structure inputs then tests, verifications, analysis - new corner stones

probablistic programs vs deterministic programs




### current techniques
- context aware
- resoning
- agent

### current fucus
 - agents
 - a2a
 - mcp
 - toolings



## idea - timeline from last presenation 



 - still a token predicting engine
    - prompt engieneering 
    - agents
    - new resoning 
    - prompt methods
    - temperature, ktop, ptop 
    - echosystem around curating the use of an llm - chain of thougth strategies 
    - different types 4o o family reasoning
    - deep seek instroduced visual resong - different languages (time?)
    - context window


- agents , mcp
    - applications of the token workflow

 - is this a real thing. Do we know better today
    - limit of data creating synthetic data, vendors of specific data
    - limit of scale of training ..
    - the foundation modelrace - china and us
    - dystopic predictions; https://ai-2027.com/ 





## arc - benchmarks 
    https://arcprize.org/
    <blockquote class="twitter-tweet" data-media-max-width="560"><p lang="en" dir="ltr">Yann LeCun: I&#39;m not interested in LLMs anymore - they&#39;re the past. The future is in four more interesting areas: machines that understand the physical world, persistent memory, reasoning, and planning. <a href="https://t.co/qRH7XVlbWq">pic.twitter.com/qRH7XVlbWq</a></p>&mdash; Victor (@victor_explore) <a href="https://twitter.com/victor_explore/status/1910978633000157201?ref_src=twsrc%5Etfw">April 12, 2025</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
    https://www.vals.ai/home

## future is this the real thing or not
    looks more plausable today 
    pivotal moments 1. ai builds ai. 2. Nationalisation of ai companies. 3 the race is on

## adoption
   rise of openai 
   rise of competition
   rise of tools 
   fortune 500 
   7 common mistakes



-- links
https://martinfowler.com/articles/deepseek-papers.html
